# ğŸš€ A800æœåŠ¡å™¨éƒ¨ç½²æŒ‡å—ï¼ˆè¶…å¿«ç‰ˆï¼‰

## ä½ çš„æœåŠ¡å™¨é…ç½®

```
ğŸ”¥ 8å— NVIDIA A800 80GB GPU
ğŸ’¾ 640GB æ€»æ˜¾å­˜
âš¡ CUDA 12.2
âœ… PyTorch 2.4.1 å·²å®‰è£…
ğŸ’¿ 1.2TB å¯ç”¨ç©ºé—´
```

**è¿™æ˜¯é¡¶é…AIè®­ç»ƒæœåŠ¡å™¨ï¼è®­ç»ƒé€Ÿåº¦æ¯”Mac M3å¿«10-20å€ï¼**

---

## ğŸ¯ å¿«é€Ÿéƒ¨ç½²ï¼ˆ3æ­¥ï¼Œ10åˆ†é’Ÿï¼‰

### æ­¥éª¤1ï¼šä¸Šä¼ å·²å¤„ç†çš„æ•°æ®ï¼ˆåœ¨Macä¸Šï¼‰

```bash
# æ–¹æ³•Aï¼šä½¿ç”¨rsyncï¼ˆæ¨èï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
cd /Users/wangbo/PycharmProjects/Chinese-dialect-recognition-with-efficientNet

# ä¸Šä¼ ä»£ç 
rsync -avz --progress retrain/ wangbo@172.22.0.35:~/dialect_training/retrain/
rsync -avz --progress train\&predict/ wangbo@172.22.0.35:~/dialect_training/train_predict/

# ä¸Šä¼ å·²å¤„ç†å¥½çš„æ•°æ®ï¼ˆ~20GBï¼Œéœ€è¦5-10åˆ†é’Ÿï¼‰
rsync -avz --progress retrain/processed_data/ \
    wangbo@172.22.0.35:~/dialect_training/retrain/processed_data/
```

### æ­¥éª¤2ï¼šSSHåˆ°æœåŠ¡å™¨å¹¶å®‰è£…ä¾èµ–

```bash
ssh wangbo@172.22.0.35
cd ~/dialect_training/retrain

# å®‰è£…ä¾èµ–ï¼ˆåªéœ€è¦ä¸€æ¬¡ï¼‰
pip3 install tensorboard seaborn scikit-learn tqdm pillow scipy numpy pandas matplotlib
```

### æ­¥éª¤3ï¼šå¯åŠ¨è®­ç»ƒğŸš€

```bash
# æ¨èé…ç½®ï¼šå•GPU B4æ¨¡å‹
CUDA_VISIBLE_DEVICES=0 nohup python3 train_improved.py \
    --data_path ./processed_data \
    --model B4 \
    --epochs 50 \
    --batch_size 256 \
    --lr 0.001 \
    --exp_name a800_training \
    --use_class_weights \
    --device cuda:0 \
    > training.log 2>&1 &

echo "è®­ç»ƒå·²å¯åŠ¨ï¼"
echo "æŸ¥çœ‹è¿›åº¦: tail -f training.log"
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| é…ç½® | è®¾å¤‡ | Batch Size | é€Ÿåº¦ | å®Œæˆæ—¶é—´ |
|------|------|-----------|------|---------|
| Mac | M3 | 24 | 1.4s/batch | 48å°æ—¶ |
| **æœåŠ¡å™¨å•GPU** | **A800** | **256** | **~0.2s/batch** | **3-4å°æ—¶** âš¡ |
| **æœåŠ¡å™¨2GPU** | **A800 x2** | **256** | **~0.1s/batch** | **1.5-2å°æ—¶** âš¡âš¡ |

---

## ğŸ” è®­ç»ƒç›‘æ§

### å®æ—¶æŸ¥çœ‹è¿›åº¦

```bash
# æŸ¥çœ‹æœ€æ–°æ—¥å¿—
tail -f ~/dialect_training/retrain/training.log

# ç›‘æ§GPUä½¿ç”¨
watch -n 1 nvidia-smi

# æŸ¥çœ‹æŒ‡å®šGPU
watch -n 1 "nvidia-smi | grep -A 5 'GPU  0'"
```

### æŸ¥çœ‹è®­ç»ƒç»Ÿè®¡

```bash
# æŸ¥çœ‹epochå®Œæˆæƒ…å†µ
grep "Epoch" ~/dialect_training/retrain/training.log | tail -20

# æŸ¥çœ‹losså˜åŒ–
grep "mean loss" ~/dialect_training/retrain/training.log | tail -50
```

---

## ğŸ’¡ æ¨èé…ç½®

### ğŸ¥‡ æ¨èï¼šå•GPU B4ï¼ˆæœ€ä½³å¹³è¡¡ï¼‰

```bash
CUDA_VISIBLE_DEVICES=0 python3 train_improved.py \
    --data_path ./processed_data \
    --model B4 \
    --epochs 50 \
    --batch_size 256 \
    --lr 0.001 \
    --use_class_weights \
    --device cuda:0
```

**ä¼˜ç‚¹**ï¼š
- å……åˆ†åˆ©ç”¨80GBæ˜¾å­˜
- é€Ÿåº¦å¿«ï¼ˆ3-4å°æ—¶ï¼‰
- ä¸å½±å“å…¶ä»–ç”¨æˆ·
- B4æ¨¡å‹ç²¾åº¦é«˜

### ğŸ¥ˆ å¤‡é€‰ï¼šå•GPU B3ï¼ˆæ›´å¿«ï¼‰

```bash
CUDA_VISIBLE_DEVICES=0 python3 train_improved.py \
    --data_path ./processed_data \
    --model B3 \
    --epochs 50 \
    --batch_size 128 \
    --lr 0.001 \
    --use_class_weights \
    --device cuda:0
```

**ä¼˜ç‚¹**ï¼š
- æ›´å¿«ï¼ˆ2-3å°æ—¶ï¼‰
- æ˜¾å­˜å ç”¨å°‘
- ç²¾åº¦ä¹Ÿä¸é”™

---

## ğŸ“¥ ä¸‹è½½è®­ç»ƒå¥½çš„æ¨¡å‹

### åœ¨Macä¸Šè¿è¡Œï¼š

```bash
# ä¸‹è½½æœ€ä½³æ¨¡å‹
scp wangbo@172.22.0.35:~/dialect_training/retrain/weights/best_model_a800_training.pth \
    /Users/wangbo/PycharmProjects/Chinese-dialect-recognition-with-efficientNet/GUI/weight/model-29.pth

# æˆ–è€…ä¸‹è½½æ‰€æœ‰æ¨¡å‹
scp wangbo@172.22.0.35:~/dialect_training/retrain/weights/*.pth \
    /Users/wangbo/PycharmProjects/Chinese-dialect-recognition-with-efficientNet/retrain/weights/
```

---

## ğŸ¯ å®Œæ•´æµç¨‹ç¤ºä¾‹

```bash
# === åœ¨Macä¸Š ===
cd /Users/wangbo/PycharmProjects/Chinese-dialect-recognition-with-efficientNet

# ä¸Šä¼ æ•°æ®å’Œä»£ç ï¼ˆä¸€æ¬¡æ€§ï¼‰
rsync -avz --progress retrain/ wangbo@172.22.0.35:~/dialect_training/retrain/
rsync -avz --progress train\&predict/ wangbo@172.22.0.35:~/dialect_training/train_predict/

# === SSHåˆ°æœåŠ¡å™¨ ===
ssh wangbo@172.22.0.35

# å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡ï¼‰
cd ~/dialect_training/retrain
pip3 install tensorboard seaborn scikit-learn tqdm pillow scipy numpy pandas matplotlib

# å¯åŠ¨è®­ç»ƒ
CUDA_VISIBLE_DEVICES=0 nohup python3 train_improved.py \
    --data_path ./processed_data \
    --model B4 \
    --epochs 50 \
    --batch_size 256 \
    --lr 0.001 \
    --exp_name a800_b4_training \
    --use_class_weights \
    --device cuda:0 \
    > training.log 2>&1 &

# æŸ¥çœ‹è¿›åº¦
tail -f training.log

# ç›‘æ§GPUï¼ˆå¦å¼€ä¸€ä¸ªç»ˆç«¯ï¼‰
watch -n 1 nvidia-smi

# === 3-4å°æ—¶åï¼Œåœ¨Macä¸Šä¸‹è½½æ¨¡å‹ ===
scp wangbo@172.22.0.35:~/dialect_training/retrain/weights/best_model_a800_b4_training.pth \
    /Users/wangbo/PycharmProjects/Chinese-dialect-recognition-with-efficientNet/GUI/weight/model-29.pth
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q: å¦‚ä½•æ£€æŸ¥è®­ç»ƒæ˜¯å¦åœ¨è¿è¡Œï¼Ÿ

```bash
ps aux | grep train_improved
nvidia-smi  # æŸ¥çœ‹GPUä½¿ç”¨ç‡
```

### Q: å¦‚ä½•åœæ­¢è®­ç»ƒï¼Ÿ

```bash
pkill -f train_improved.py
```

### Q: å¦‚ä½•ä½¿ç”¨å¤šGPUï¼Ÿ

```bash
# ä½¿ç”¨2å—GPU
CUDA_VISIBLE_DEVICES=0,1 python3 -m torch.distributed.launch \
    --nproc_per_node=2 \
    train_improved.py \
    --data_path ./processed_data \
    --model B4 \
    --batch_size 256 \
    --device cuda \
    [å…¶ä»–å‚æ•°...]
```

### Q: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

```bash
# å‡å°batch size
--batch_size 128  # æˆ– 64

# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
--model B3  # æˆ– B0
```

---

## ğŸ“ˆ é¢„æœŸç»“æœ

### è®­ç»ƒå®Œæˆååº”è¯¥çœ‹åˆ°ï¼š

```
Epoch 49/50 å®Œæˆ
éªŒè¯å‡†ç¡®ç‡: 88-92%
è®­ç»ƒæŸå¤±: < 0.5
æœ€ä½³æ¨¡å‹å·²ä¿å­˜: weights/best_model_a800_b4_training.pth

å„æ–¹è¨€å‡†ç¡®ç‡:
  å››å·è¯: 90%+  â† ä¸»è¦ç›®æ ‡
  å®¢å®¶è¯: 88%+
  ...
```

### æ”¹è¿›å¯¹æ¯”ï¼š

| æŒ‡æ ‡ | æ—§æ¨¡å‹ | æ–°æ¨¡å‹ï¼ˆé¢„æœŸï¼‰|
|------|--------|--------------|
| å››å·è¯å‡†ç¡®ç‡ | ~0% | 90%+ â¬†ï¸â¬†ï¸â¬†ï¸ |
| æ€»ä½“å‡†ç¡®ç‡ | 78% | 88-92% â¬†ï¸ |
| æ•°æ®é‡ | 250å¼ /ç±» | 6500å¼ /ç±» |

---

## ğŸŠ æ€»ç»“

### ä½ çš„ä¼˜åŠ¿ï¼š
1. âš¡ **A800 GPU** - é¡¶çº§è®­ç»ƒå¡
2. ğŸ’¾ **80GBæ˜¾å­˜** - å¯ä»¥ç”¨è¶…å¤§batch size
3. ğŸš€ **é€Ÿåº¦å¿«10-20å€** - 3-4å°æ—¶vs 48å°æ—¶
4. ğŸ“Š **æ•°æ®å……è¶³** - 65,000å¼ å£°è°±å›¾

### æ¨èè¡ŒåŠ¨ï¼š
1. âœ… ç«‹å³ä¸Šä¼ æ•°æ®åˆ°æœåŠ¡å™¨
2. âœ… ä½¿ç”¨å•GPU B4é…ç½®è®­ç»ƒ
3. âœ… 3-4å°æ—¶åä¸‹è½½æ–°æ¨¡å‹
4. âœ… æµ‹è¯•å››å·è¯è¯†åˆ«æ•ˆæœ

**é¢„è®¡ä»Šæ™šå°±èƒ½å®Œæˆè®­ç»ƒï¼** ğŸ‰

---

éœ€è¦å¸®åŠ©ï¼Ÿæä¾›è¿™äº›ä¿¡æ¯ï¼š
- `nvidia-smi` è¾“å‡º
- `tail -100 training.log`
- é”™è¯¯ä¿¡æ¯


