"""
éŸ³é¢‘æ–‡ä»¶è¯Šæ–­å·¥å…·
æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦ç¬¦åˆè¯†åˆ«è¦æ±‚
"""

import sys
import os
import wave
import numpy as np
import scipy.io.wavfile as wav
from PIL import Image
import matplotlib.pyplot as plt


def analyze_audio(audio_path):
    """åˆ†æéŸ³é¢‘æ–‡ä»¶"""
    print("\n" + "="*60)
    print(f"éŸ³é¢‘æ–‡ä»¶è¯Šæ–­: {os.path.basename(audio_path)}")
    print("="*60)
    
    if not os.path.exists(audio_path):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {audio_path}")
        return
    
    try:
        # è¯»å–WAVæ–‡ä»¶åŸºæœ¬ä¿¡æ¯
        with wave.open(audio_path, 'rb') as wf:
            channels = wf.getnchannels()
            sample_width = wf.getsampwidth()
            framerate = wf.getframerate()
            n_frames = wf.getnframes()
            duration = n_frames / framerate
            
        print(f"\nğŸ“Š åŸºæœ¬ä¿¡æ¯:")
        print(f"  å£°é“æ•°: {channels} ({'å•å£°é“' if channels == 1 else 'å¤šå£°é“'})")
        print(f"  é‡‡æ ·ä½æ•°: {sample_width * 8} bit")
        print(f"  é‡‡æ ·ç‡: {framerate} Hz")
        print(f"  æ€»å¸§æ•°: {n_frames}")
        print(f"  æ—¶é•¿: {duration:.2f} ç§’")
        
        # æ£€æŸ¥æ—¶é•¿
        if duration < 5:
            print(f"  âš ï¸  è­¦å‘Š: æ—¶é•¿å¤ªçŸ­ ({duration:.2f}ç§’)ï¼Œå»ºè®®5-10ç§’")
        elif duration > 10:
            print(f"  âš ï¸  è­¦å‘Š: æ—¶é•¿å¤ªé•¿ ({duration:.2f}ç§’)ï¼Œå»ºè®®5-10ç§’")
        else:
            print(f"  âœ“ æ—¶é•¿åˆé€‚")
        
        # æ£€æŸ¥é‡‡æ ·ç‡
        if framerate < 16000:
            print(f"  âš ï¸  è­¦å‘Š: é‡‡æ ·ç‡è¾ƒä½ ({framerate} Hz)ï¼Œå»ºè®®16000 Hzä»¥ä¸Š")
        else:
            print(f"  âœ“ é‡‡æ ·ç‡åˆé€‚")
        
        # è¯»å–éŸ³é¢‘æ•°æ®
        samplerate, samples = wav.read(audio_path)
        
        # è½¬æ¢ä¸ºå•å£°é“
        if len(samples.shape) > 1:
            samples = samples[:, 0]
        
        # è®¡ç®—éŸ³é‡ç»Ÿè®¡
        samples_float = samples.astype(float)
        max_amplitude = np.max(np.abs(samples_float))
        mean_amplitude = np.mean(np.abs(samples_float))
        
        # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        if sample_width == 2:  # 16-bit
            max_possible = 32768.0
        else:
            max_possible = 256.0
        
        max_volume = max_amplitude / max_possible
        mean_volume = mean_amplitude / max_possible
        
        print(f"\nğŸ”Š éŸ³é‡åˆ†æ:")
        print(f"  æœ€å¤§éŸ³é‡: {max_volume:.2%}")
        print(f"  å¹³å‡éŸ³é‡: {mean_volume:.2%}")
        
        if max_volume < 0.1:
            print(f"  âš ï¸  è­¦å‘Š: éŸ³é‡å¤ªå°ï¼Œå¯èƒ½å½±å“è¯†åˆ«")
        elif max_volume > 0.95:
            print(f"  âš ï¸  è­¦å‘Š: éŸ³é‡å¯èƒ½è¿‡è½½")
        else:
            print(f"  âœ“ éŸ³é‡æ­£å¸¸")
        
        # è®¡ç®—ä¿¡å™ªæ¯”ä¼°è®¡
        # ä½¿ç”¨èƒ½é‡æ³•ä¼°è®¡
        energy = np.sum(samples_float ** 2) / len(samples_float)
        noise_estimate = np.percentile(np.abs(samples_float), 10)  # ä½¿ç”¨10%åˆ†ä½æ•°ä¼°è®¡å™ªå£°
        
        if noise_estimate > 0:
            snr_estimate = 20 * np.log10(max_amplitude / noise_estimate)
            print(f"\nğŸ“¡ ä¿¡å™ªæ¯”ä¼°è®¡:")
            print(f"  SNR: {snr_estimate:.1f} dB")
            
            if snr_estimate < 10:
                print(f"  âš ï¸  è­¦å‘Š: å™ªå£°è¾ƒå¤§ï¼Œå»ºè®®åœ¨å®‰é™ç¯å¢ƒå½•éŸ³")
            elif snr_estimate < 20:
                print(f"  âš ï¸  æ³¨æ„: æœ‰ä¸€å®šèƒŒæ™¯å™ªéŸ³")
            else:
                print(f"  âœ“ ä¿¡å™ªæ¯”è‰¯å¥½")
        
        # é™éŸ³æ£€æµ‹
        silence_threshold = max_amplitude * 0.05
        silence_frames = np.sum(np.abs(samples_float) < silence_threshold)
        silence_ratio = silence_frames / len(samples_float)
        
        print(f"\nğŸ”‡ é™éŸ³åˆ†æ:")
        print(f"  é™éŸ³æ¯”ä¾‹: {silence_ratio:.1%}")
        
        if silence_ratio > 0.5:
            print(f"  âš ï¸  è­¦å‘Š: é™éŸ³è¿‡å¤š ({silence_ratio:.1%})ï¼Œå¯èƒ½å½•éŸ³å¤±è´¥")
        elif silence_ratio > 0.3:
            print(f"  âš ï¸  æ³¨æ„: é™éŸ³è¾ƒå¤š")
        else:
            print(f"  âœ“ è¯­éŸ³å†…å®¹å……è¶³")
        
        # é¢‘ç‡åˆ†æ
        fft = np.fft.fft(samples_float)
        freqs = np.fft.fftfreq(len(samples_float), 1/samplerate)
        
        # åªçœ‹æ­£é¢‘ç‡
        positive_freqs = freqs[:len(freqs)//2]
        positive_fft = np.abs(fft[:len(fft)//2])
        
        # æ‰¾åˆ°ä¸»è¦é¢‘ç‡
        dominant_freq_idx = np.argmax(positive_fft)
        dominant_freq = positive_freqs[dominant_freq_idx]
        
        print(f"\nğŸµ é¢‘ç‡åˆ†æ:")
        print(f"  ä¸»è¦é¢‘ç‡: {abs(dominant_freq):.0f} Hz")
        
        # äººå£°ä¸€èˆ¬åœ¨85-255 Hz (åŸºé¢‘)
        if 85 <= abs(dominant_freq) <= 255:
            print(f"  âœ“ é¢‘ç‡èŒƒå›´ç¬¦åˆäººå£°ç‰¹å¾")
        else:
            print(f"  âš ï¸  æ³¨æ„: ä¸»é¢‘ç‡ä¸åœ¨å…¸å‹äººå£°èŒƒå›´")
        
        # ç»¼åˆè¯„åˆ†
        print(f"\nğŸ“ˆ ç»¼åˆè¯„ä¼°:")
        score = 100
        issues = []
        
        if duration < 5 or duration > 10:
            score -= 20
            issues.append("æ—¶é•¿ä¸åˆé€‚")
        
        if max_volume < 0.1:
            score -= 25
            issues.append("éŸ³é‡å¤ªå°")
        
        if silence_ratio > 0.5:
            score -= 30
            issues.append("é™éŸ³è¿‡å¤š")
        
        if framerate < 16000:
            score -= 15
            issues.append("é‡‡æ ·ç‡åä½")
        
        print(f"  è´¨é‡è¯„åˆ†: {score}/100")
        
        if score >= 80:
            print(f"  âœ“ éŸ³é¢‘è´¨é‡è‰¯å¥½ï¼Œé€‚åˆè¯†åˆ«")
        elif score >= 60:
            print(f"  âš ï¸  éŸ³é¢‘è´¨é‡ä¸€èˆ¬ï¼Œå¯èƒ½å½±å“è¯†åˆ«å‡†ç¡®åº¦")
            print(f"  é—®é¢˜: {', '.join(issues)}")
        else:
            print(f"  âŒ éŸ³é¢‘è´¨é‡è¾ƒå·®ï¼Œå»ºè®®é‡æ–°å½•åˆ¶")
            print(f"  é—®é¢˜: {', '.join(issues)}")
        
        print("\n" + "="*60)
        
        # å»ºè®®
        print("\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        if duration < 5:
            print("  â€¢ å¢åŠ å½•éŸ³æ—¶é•¿åˆ°5-10ç§’")
        if max_volume < 0.1:
            print("  â€¢ å¢åŠ éº¦å…‹é£éŸ³é‡æˆ–é è¿‘éº¦å…‹é£")
        if silence_ratio > 0.3:
            print("  â€¢ å‡å°‘å½•éŸ³å‰åçš„åœé¡¿ï¼Œä¿æŒè¿ç»­è¯´è¯")
        if framerate < 16000:
            print("  â€¢ ä½¿ç”¨æ›´é«˜çš„é‡‡æ ·ç‡å½•éŸ³ï¼ˆå»ºè®®16000 Hzæˆ–48000 Hzï¼‰")
        if noise_estimate / max_possible > 0.05:
            print("  â€¢ åœ¨æ›´å®‰é™çš„ç¯å¢ƒä¸­å½•éŸ³")
        
        print("  â€¢ è¯´è¯æ¸…æ™°ã€å‘éŸ³æ ‡å‡†")
        print("  â€¢ ä½¿ç”¨å…¸å‹çš„æ–¹è¨€è¯æ±‡å’Œè¯­è°ƒ")
        print("  â€¢ ä¿æŒç¨³å®šçš„è¯­é€Ÿ")
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def visualize_audio(audio_path):
    """å¯è§†åŒ–éŸ³é¢‘æ³¢å½¢"""
    try:
        samplerate, samples = wav.read(audio_path)
        
        if len(samples.shape) > 1:
            samples = samples[:, 0]
        
        time = np.linspace(0, len(samples) / samplerate, num=len(samples))
        
        plt.figure(figsize=(12, 4))
        plt.plot(time, samples)
        plt.xlabel('æ—¶é—´ (ç§’)')
        plt.ylabel('æŒ¯å¹…')
        plt.title(f'éŸ³é¢‘æ³¢å½¢ - {os.path.basename(audio_path)}')
        plt.grid(True, alpha=0.3)
        
        output_path = audio_path.replace('.wav', '_waveform.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"\næ³¢å½¢å›¾å·²ä¿å­˜: {output_path}")
        
        plt.close()
        
    except Exception as e:
        print(f"æ³¢å½¢å¯è§†åŒ–å¤±è´¥: {e}")


if __name__ == '__main__':
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python diagnose_audio.py <éŸ³é¢‘æ–‡ä»¶.wav>")
        print("ç¤ºä¾‹: python diagnose_audio.py test.wav")
        sys.exit(1)
    
    audio_file = sys.argv[1]
    analyze_audio(audio_file)
    
    # è¯¢é—®æ˜¯å¦ç”Ÿæˆæ³¢å½¢å›¾
    if len(sys.argv) > 2 and sys.argv[2] == '--visualize':
        visualize_audio(audio_file)


